{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. generate training samples (scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from ruixuan.turning_scene import *\n",
    "from l5kit.rasterization.rasterizer_builder import _load_metadata\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from tabulate import tabulate\n",
    "from utils import Gibbs_sampling\n",
    "from config import Config\n",
    "from visualizer import plot_scene_on_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab1/miniconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator BayesianGaussianMixture from version 0.24.1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pxy= pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_Pxy.pickle\",'rb'))\n",
    "pxz= pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_Pxz.pickle\",'rb'))\n",
    "pyzx= pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_Pyzx.pickle\",'rb'))\n",
    "\n",
    "veh_model = pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_veh_model.pickle\",'rb'))\n",
    "ped_model = pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_ped_model.pickle\",'rb'))\n",
    "cyc_model = pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_cyc_model.pickle\",'rb'))\n",
    "\n",
    "poolv = pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_veh_pool.pickle\",'rb'))\n",
    "poolp = pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_ped_pool.pickle\",'rb'))\n",
    "poolc = pickle.load(open(\"/home/lab1/repo/planning/saved_gibbs/8kfb_cyc_pool.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_res = Gibbs_sampling(max_scene=20, Pxy=pxy, Pxz=pxz, Pyzx=pyzx, poolv=poolv, poolp=poolp, poolc=poolc,\\\n",
    "                             veh_model = veh_model, ped_model=ped_model, cyc_model=cyc_model,\\\n",
    "                             max_n_veh=10, max_n_ped=5,max_n_cyc=5)\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 20, 2) (5, 20, 2) (1, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "scene_data  = sampling_res[18]\n",
    "veh_s = scene_data['veh']\n",
    "np.random.shuffle(veh_s)\n",
    "ped_s = scene_data['ped']\n",
    "cyc_s = scene_data['cyc']\n",
    "print(veh_s.shape, ped_s.shape, cyc_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_scene_on_grid('8KfB', lane_list=cfg.lane_list, \\\n",
    "#                            grid_boundary=cfg.grid_boundary, Test=cfg.Test, veh=veh_s[:], ped=ped_s, cyc=cyc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "# x=list(itertools.product([1,2], [2,3]))\n",
    "# x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. construct graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pred_veh(pred_model_v, traj):\n",
    "    pass \n",
    "def pred_risk(risk_model, traj):\n",
    "    pass\n",
    "def pred_ped(pred_model_p, traj):\n",
    "    pass \n",
    "def pred_cyc(pred_model_c, traj):\n",
    "    pass \n",
    "\n",
    "def compute_vweight(target, veh):\n",
    "    \"\"\"\n",
    "    computes the edge weights between target and veh\n",
    "    \"\"\"\n",
    "    pos = target.pos\n",
    "    pass\n",
    "    \n",
    "def compute_pcweight(target, pc):\n",
    "    \"\"\"\n",
    "    computes the edge weights between target and ped/cyc\n",
    "    \"\"\"\n",
    "    pos = target.pos\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planned subject: \n",
    "# pick a left/right/straight trajectory to plan\n",
    "\n",
    "class TargetNode():\n",
    "    \"\"\"\n",
    "    build target node\n",
    "    \"\"\"\n",
    "    def __init__(self, traj):\n",
    "        self.start=traj[10] # position at 5th second\n",
    "        self.goal=traj[-1] # last point\n",
    "        self.pos=self.start\n",
    "        self.task=np.array(self.start,self.goal)\n",
    "  \n",
    "        self.a,self.v = self._get_av(traj[8], traj[9], traj[10])\n",
    "        self.theta = self._get_theta(traj[9], traj[10])\n",
    "        self.t=0\n",
    "        \n",
    "        self.history=[]\n",
    "        self.history.append([self.t, self.pos, self.a, self.theta])\n",
    "        \n",
    "        \n",
    "    def _get_av(self, prev2, prev, curr):\n",
    "        v10 = np.linalg.norm(curr - prev)/0.5\n",
    "        v9 = np.linalg.norm(prev - prev2)/0.5\n",
    "        a = (v10-v9)/0.5\n",
    "        return a, v10\n",
    "    \n",
    "    def _get_theta(self, prev,curr):\n",
    "        try:\n",
    "            tan = (curr[1]-prev[1])/(curr[0]-prev[0])\n",
    "            return math.atan(tan)\n",
    "        except:\n",
    "            return 90\n",
    "        \n",
    "class Node():\n",
    "    \"\"\"\n",
    "    build other nodes\n",
    "    \"\"\"\n",
    "    def __init__(self,traj, pred, agent='veh',risk=0.5):\n",
    "        self.traj=traj\n",
    "        self.pred=pred\n",
    "        self.agent=agent\n",
    "        if agent=='veh':\n",
    "            self.risk=risk\n",
    "        else:\n",
    "            # if agent==veh, there is risk, otherwise the risk is not meaningful\n",
    "            self.risk=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self, sample, models, lane_boundary):\n",
    "        self.sample=sample\n",
    "        self.graph={}\n",
    "        self.vmodel=models[0]\n",
    "        self.pmodel=models[1]\n",
    "        self.cmodel=models[2]\n",
    "        self.riskmodel=models[3]\n",
    "        self.lane_boundary=lane_boundary\n",
    "        \n",
    "        self.action_dict = list(itertools.product(range(-3,3,0.1), range(0,180,1)))\n",
    "        \n",
    "        return self._build_graph_\n",
    "        \n",
    "    def _build_graph_(self):\n",
    "        subject = sample['veh'][0]\n",
    "        self.target= TargetNode(subject)\n",
    "        self.env_veh=[]\n",
    "        self.env_ped=[]\n",
    "        self.env_cyc=[]\n",
    "        self.edges=[]\n",
    "        \n",
    "        # build nodes/vertices\n",
    "        for i in range(1, len(self.sample['veh'])):\n",
    "            traj = self.sample['veh'][i]\n",
    "            pred_traj = pred_veh(self.vmodel, traj)\n",
    "            risk = pred_risk(self.riskmodel, traj)\n",
    "            node = Node(traj,pred_traj,'veh',risk)\n",
    "            self.env_veh.append(node)\n",
    "            \n",
    "        \n",
    "        for traj in samples['cyc']:\n",
    "            pred_traj = pred_cyc(self.cmodel,traj)\n",
    "            node=Node(traj, pred_traj,'cyc')\n",
    "            self.env_cyc.append(node)\n",
    "            \n",
    "    \n",
    "        for traj in samples['ped']:\n",
    "            pred_traj = pred_cyc(self.pmodel,traj)\n",
    "            node=Node(traj, pred_traj,'ped')\n",
    "            self.env_ped.append(node)\n",
    "            \n",
    "        self._update_edges()\n",
    "        # build edges\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def _update_edges(self):\n",
    "        \n",
    "        for node in self.env_veh:\n",
    "            weight = compute_vweight(self.target, node)\n",
    "            self.edges.append(weight)\n",
    "            \n",
    "        for node in self.env_cyc:\n",
    "            weight = compute_pcweight(self.target, node)\n",
    "            self.edges.append(weight)\n",
    "            \n",
    "        for node in self.env_ped:\n",
    "            weight = compute_pcweight(self.target, node)\n",
    "            self.edges.append(weight)\n",
    "    \n",
    "    def _take_action(self, policy):\n",
    "        \n",
    "        # action = self.take_action(policy)\n",
    "        # return action\n",
    "        pass\n",
    "    \n",
    "    def is_crash(self):\n",
    "        \"\"\"\n",
    "        check if crash happens when graph is updated, or hit lane_boundary inside intersection\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def step(self, action, policy):\n",
    "        \"\"\"\n",
    "        update graph, move to next state\n",
    "        action space [-3, 3] * [0,180] => 60*180 action space\n",
    "        \"\"\"\n",
    "        acc, theta = self.action_dict[action]\n",
    "        distance = self.target.v*0.5+0.5*acc*0.25\n",
    "        radian = theta*math.pi/180\n",
    "        dx, dy = distance*math.cos(radian), distance*math.sin(radian)\n",
    "        \n",
    "        #update state\n",
    "        self.target.pos =[self.target.pos[0]+dx, self.target.pos[1]+dy]\n",
    "        self.target.v = self.target.v+acc*0.5\n",
    "        self.target.a = acc\n",
    "        self.target.theta=theta\n",
    "        self.target.t +=1\n",
    "\n",
    "        self.target.history.append([self.target.t, self.target.pos, self.target.a, self.target.theta])\n",
    "        # update the state\n",
    "        self._update_edges()  #maybe put to later\n",
    "        distance_to_goal = np.linalg.norm(self.target.pos - self.target.goal, axis=1)\n",
    "        \n",
    "        # compute reward\n",
    "        # stop crateria: #step longer than 5 seconds, reached goal, crash with other agents\n",
    "        if  distance_to_goal<1:\n",
    "            # update reward\n",
    "            pass\n",
    "        \n",
    "        elif self.t>10:\n",
    "            # update reward\n",
    "             #return 'done'\n",
    "            pass\n",
    "        elif is_crash():  \n",
    "            # this can be moved to update edge part by giving a huge loss, is the loss pass the threshold then done\n",
    "            # update reward\n",
    "            pass\n",
    "        else:\n",
    "            # update reward\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    def _get_reward(self):\n",
    "        \"\"\"\n",
    "        compute cost of the current state, A*sum_t sum_edge c_pi +B*c_goal +C* c_smoothness\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map graph to states with clustering to fit into reinforcement learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.        ]\n",
      " [3.16227766 1.         1.        ]\n",
      " [2.         0.         0.        ]] [1. 1. 0.] 2.0\n"
     ]
    }
   ],
   "source": [
    "from tslearn.metrics import dtw,cdist_dtw\n",
    "# \n",
    "a=[[2,3], 1,2]\n",
    "b=[[2,4],2,2]\n",
    "s= cdist_dtw(a,b, n_jobs=-1)\n",
    "amin = np.amin(s, axis=1)\n",
    "print(s,amin, sum(amin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(a,b):\n",
    "    s= cdist_dtw(a,b, n_jobs=-1)\n",
    "    amin = np.amin(s, axis=1)\n",
    "#     print(s,amin, sum(amin))\n",
    "    # sum the diagno of the cdist_dtw matrix\n",
    "    return sum(amin)\n",
    "\n",
    "def compute_similarity(g1, g2):\n",
    "    \"\"\"\n",
    "    compute the similarity between two graphs\n",
    "    final similarity between two graphs:\n",
    "    s = w1* similarity_between_target_nodes + \n",
    "    w2*[similarity_between_veh_nodes +\n",
    "    similarity_between_ped_nodes +\n",
    "    similarity_between_cyc_nodes] +\n",
    "    w3* similarity_between_edges\n",
    "    \n",
    "    helper for formulating states, give a good reward signal, the states should transit closer to goal\n",
    "    \"\"\"\n",
    "    # focusing on subject, but the similarity is regularized by envronment\n",
    "    # target_sim\n",
    "    target_task_s = get_sim(g1.target.goal,g2.target.goal)\n",
    "    g1t_attr = [g1.target.pos, g1.target.a, g1.target.theta/180]\n",
    "    g2t_attr = [g2.target.pos, g2.target.a, g2.target.theta/180]\n",
    "    target_attr_s =get_sim(g1t_attr, g2t_attr)\n",
    "    subject_sim = target_task_s + target_attr_s\n",
    "    # veh_sim\n",
    "    veh_traj =[]\n",
    "    for node in g1.env_veh:\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
