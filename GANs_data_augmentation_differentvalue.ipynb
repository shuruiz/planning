{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM,Bidirectional\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Flatten, Reshape\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D,concatenate\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import math\n",
    "import pickle5 as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "checking gpu error\n",
      "checking GPUs\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:06:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    except:\n",
    "        print('checking gpu error')\n",
    "print('checking GPUs')\n",
    "\n",
    "config=tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.visible_device_list= '0,1'\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "config.log_device_placement=True\n",
    "# config.visible_device_list =2\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setting\n",
    "sample_size = 10000\n",
    "num_per_channel=3\n",
    "x_column=150\n",
    "y_column=150\n",
    "channels=40\n",
    "sample_shape= (num_per_channel, channels, x_column, y_column, )\n",
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(img_shape, z_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=z_dim))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(num_per_channel*x_column*y_column*channels, activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "    z = Input(shape=(z_dim,))\n",
    "    img = model(z)\n",
    "    return Model(z, img)\n",
    "\n",
    "def discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    img = Input(shape=img_shape)\n",
    "    prediction = model(img)\n",
    "    return Model(img, prediction)\n",
    "\n",
    "discriminator = discriminator(sample_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "generator = generator(sample_shape, z_dim)\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "prediction = discriminator(img)\n",
    "combined = Model(z, prediction)\n",
    "combined.compile(loss='cosine_similarity', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "def train(iterations, batch_size, sample_interval,xtrain, xtest):\n",
    "    gen_images = []\n",
    "    \n",
    "    # Assign X_train to X_train_0 for augment non-cactus images\n",
    "    # Assign X_train to X_train_1 for augment cactus images\n",
    "\n",
    "    X_train = np.array(xtrain)\n",
    "    X_test = np.array(xtest)\n",
    "    real = np.ones((batch_size, 1))\n",
    "#     real = np.random.choice(X_train, size=batch_size, replace=True, p=None)\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "       \n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(z)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "#         d_loss = discriminator.train_on_batch(gen_imgs, real)\n",
    "\n",
    "        z = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(z)\n",
    "        g_loss = combined.train_on_batch(z, real)\n",
    "\n",
    "        if iteration % sample_interval == 0:\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            losses.append((d_loss[0], g_loss))\n",
    "            accuracies.append(100*d_loss[1])\n",
    "            gen_images.append(sample_images(iteration))\n",
    "    return gen_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_images(iteration, image_grid_rows=4, image_grid_columns=4):\n",
    "\n",
    "    z = np.random.normal(0, 1, \n",
    "              (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    gen_imgs = generator.predict(z)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "            \n",
    "    return gen_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 3, 40, 150, 150)\n",
      "0 [D loss: 0.694419, acc.: 37.50%] [G loss: 29.163464]\n",
      "5 [D loss: 0.168225, acc.: 93.75%] [G loss: 517.086670]\n",
      "10 [D loss: 57.198887, acc.: 43.75%] [G loss: 32.832928]\n",
      "15 [D loss: 0.237530, acc.: 87.50%] [G loss: 5079.279297]\n",
      "20 [D loss: 6.631823, acc.: 68.75%] [G loss: 2717.189209]\n",
      "25 [D loss: 175.874738, acc.: 37.50%] [G loss: 2452.010010]\n",
      "30 [D loss: 260.521243, acc.: 6.25%] [G loss: 2809.386230]\n",
      "35 [D loss: 436.220895, acc.: 18.75%] [G loss: 5057.897461]\n",
      "40 [D loss: 129.343550, acc.: 37.50%] [G loss: 5637.686523]\n",
      "45 [D loss: 0.447329, acc.: 75.00%] [G loss: 3652.018555]\n",
      "50 [D loss: 1.443372, acc.: 68.75%] [G loss: 12345.046875]\n",
      "55 [D loss: 0.737081, acc.: 75.00%] [G loss: 2467.038574]\n",
      "60 [D loss: 0.181273, acc.: 93.75%] [G loss: 10005.908203]\n",
      "65 [D loss: 169.537835, acc.: 75.00%] [G loss: 3749.231201]\n",
      "70 [D loss: 0.085701, acc.: 100.00%] [G loss: 23800.886719]\n",
      "75 [D loss: 0.283512, acc.: 93.75%] [G loss: 23966.410156]\n",
      "80 [D loss: 0.189413, acc.: 93.75%] [G loss: 12210.989258]\n",
      "85 [D loss: 0.127610, acc.: 100.00%] [G loss: 11507.351562]\n",
      "90 [D loss: 0.113324, acc.: 100.00%] [G loss: 7235.554199]\n",
      "95 [D loss: 0.042038, acc.: 100.00%] [G loss: 13938.231445]\n",
      "100 [D loss: 0.115339, acc.: 100.00%] [G loss: 32495.550781]\n",
      "105 [D loss: 0.232278, acc.: 93.75%] [G loss: 33897.468750]\n",
      "110 [D loss: 0.092429, acc.: 100.00%] [G loss: 29614.023438]\n",
      "115 [D loss: 0.087716, acc.: 100.00%] [G loss: 24812.742188]\n",
      "120 [D loss: 0.132887, acc.: 100.00%] [G loss: 17008.593750]\n",
      "125 [D loss: 0.034630, acc.: 100.00%] [G loss: 10932.924805]\n",
      "130 [D loss: 0.047634, acc.: 100.00%] [G loss: 8361.773438]\n",
      "135 [D loss: 0.039318, acc.: 100.00%] [G loss: 2736.862305]\n",
      "140 [D loss: 0.077188, acc.: 100.00%] [G loss: 54775.644531]\n",
      "145 [D loss: 0.115255, acc.: 93.75%] [G loss: 84445.710938]\n",
      "150 [D loss: 0.176713, acc.: 100.00%] [G loss: 84532.226562]\n",
      "155 [D loss: 0.064671, acc.: 100.00%] [G loss: 77832.546875]\n",
      "160 [D loss: 0.282257, acc.: 93.75%] [G loss: 66891.937500]\n",
      "165 [D loss: 0.114763, acc.: 100.00%] [G loss: 48506.781250]\n",
      "170 [D loss: 0.082711, acc.: 100.00%] [G loss: 37182.523438]\n",
      "175 [D loss: 0.100705, acc.: 100.00%] [G loss: 32342.218750]\n",
      "180 [D loss: 0.092465, acc.: 100.00%] [G loss: 17352.978516]\n",
      "185 [D loss: 0.083947, acc.: 100.00%] [G loss: 25644.158203]\n",
      "190 [D loss: 0.082698, acc.: 100.00%] [G loss: 18624.291016]\n",
      "195 [D loss: 0.062788, acc.: 100.00%] [G loss: 13649.693359]\n",
      "200 [D loss: 0.059458, acc.: 100.00%] [G loss: 10299.276367]\n",
      "205 [D loss: 0.065817, acc.: 100.00%] [G loss: 5104.869629]\n",
      "210 [D loss: 0.127500, acc.: 93.75%] [G loss: 2968.999023]\n",
      "215 [D loss: 0.055579, acc.: 100.00%] [G loss: 4602.959473]\n",
      "220 [D loss: 0.097257, acc.: 100.00%] [G loss: 4791.841309]\n",
      "225 [D loss: 0.105049, acc.: 100.00%] [G loss: 2460.462402]\n",
      "230 [D loss: 0.081210, acc.: 100.00%] [G loss: 1435.091797]\n",
      "235 [D loss: 0.104766, acc.: 100.00%] [G loss: 1786.131714]\n",
      "240 [D loss: 0.083724, acc.: 100.00%] [G loss: 2365.674561]\n",
      "245 [D loss: 0.051048, acc.: 100.00%] [G loss: 1480.954590]\n",
      "250 [D loss: 0.057557, acc.: 100.00%] [G loss: 1328.767578]\n",
      "255 [D loss: 0.065354, acc.: 100.00%] [G loss: 1319.072510]\n",
      "260 [D loss: 0.059590, acc.: 100.00%] [G loss: 728.812012]\n",
      "265 [D loss: 0.044183, acc.: 100.00%] [G loss: 642.973633]\n",
      "270 [D loss: 0.033766, acc.: 100.00%] [G loss: 512.422729]\n",
      "275 [D loss: 0.054880, acc.: 100.00%] [G loss: 383.577393]\n",
      "280 [D loss: 0.061254, acc.: 100.00%] [G loss: 2509.514893]\n",
      "285 [D loss: 0.064933, acc.: 100.00%] [G loss: 3795.111328]\n",
      "290 [D loss: 0.065553, acc.: 100.00%] [G loss: 4989.191895]\n",
      "295 [D loss: 0.051188, acc.: 100.00%] [G loss: 4008.683105]\n",
      "300 [D loss: 0.068959, acc.: 100.00%] [G loss: 4959.702148]\n",
      "305 [D loss: 0.038857, acc.: 100.00%] [G loss: 3649.799316]\n",
      "310 [D loss: 0.046901, acc.: 100.00%] [G loss: 4638.969727]\n",
      "315 [D loss: 0.024381, acc.: 100.00%] [G loss: 4376.931641]\n",
      "320 [D loss: 0.037994, acc.: 100.00%] [G loss: 3893.869141]\n",
      "325 [D loss: 0.034553, acc.: 100.00%] [G loss: 2909.847656]\n",
      "330 [D loss: 0.051704, acc.: 100.00%] [G loss: 3070.874512]\n",
      "335 [D loss: 0.030347, acc.: 100.00%] [G loss: 2832.928955]\n",
      "340 [D loss: 0.021303, acc.: 100.00%] [G loss: 2535.241211]\n",
      "345 [D loss: 0.031383, acc.: 100.00%] [G loss: 2093.797852]\n",
      "350 [D loss: 0.038434, acc.: 100.00%] [G loss: 2084.449951]\n",
      "355 [D loss: 0.034894, acc.: 100.00%] [G loss: 2477.692383]\n",
      "360 [D loss: 0.029368, acc.: 100.00%] [G loss: 2085.309814]\n",
      "365 [D loss: 0.053235, acc.: 100.00%] [G loss: 2009.017578]\n",
      "370 [D loss: 0.071231, acc.: 100.00%] [G loss: 1401.338379]\n",
      "375 [D loss: 0.014680, acc.: 100.00%] [G loss: 1185.863037]\n",
      "380 [D loss: 0.013595, acc.: 100.00%] [G loss: 775.727905]\n"
     ]
    }
   ],
   "source": [
    "# Set iterations at least 10000 for good results\n",
    "iterations = 200\n",
    "batch_size = 8\n",
    "sample_interval = 5\n",
    "xtrain = np.load('8kfb_representation_samevalue.npy', allow_pickle=True)\n",
    "print(xtrain.shape)\n",
    "np.random.shuffle(xtrain)\n",
    "split = math.floor(len(xtrain)*0.9)\n",
    "xtrain, xtest = xtrain[:split], xtrain[split:]\n",
    "gen_imgs = train(iterations, batch_size, sample_interval, xtrain,xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(0, 1, (batch_size, 100))\n",
    "output = generator.predict(z)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replot from representation\n",
    "from collections import defaultdict\n",
    "def find_traj(tensor):\n",
    "#     print(tensor.shape)\n",
    "    result_traj=defaultdict(list) #{id:traj}, traj is 2D\n",
    "    for snapshot in tensor:\n",
    "        max_v = int(np.max(snapshot))\n",
    "        if max_v==0:\n",
    "            continue\n",
    "        for value in range(1, max_v+1):\n",
    "#             print(value)\n",
    "            loc = np.where(snapshot==value)\n",
    "            if loc[0].size==0:\n",
    "                continue\n",
    "            result_traj[value].append([loc[0][0]+450, loc[1][0]-2450])\n",
    "    return result_traj\n",
    "            \n",
    "    \n",
    "def replot_from_representation(scene_tensor, lane_list, intersection_id, grid_boundary):\n",
    "\n",
    "    veh, ped, cyc = scene_tensor[0], scene_tensor[1], scene_tensor[2]\n",
    "    veh_traj = find_traj(veh)\n",
    "    ped_traj = find_traj(ped)\n",
    "    cyc_traj = find_traj(cyc)\n",
    "    \n",
    "    plt.figure(figsize=(18,18))\n",
    "    for lane in lane_list[intersection_id]:\n",
    "        plt.plot(Test.map_api.get_lane_coords(lane)['xyz_right'][:,0], Test.map_api.get_lane_coords(lane)['xyz_right'][:,1],\n",
    "                 color='g',linewidth=1,label=lane)\n",
    "        plt.plot(Test.map_api.get_lane_coords(lane)['xyz_left'][:,0], Test.map_api.get_lane_coords(lane)['xyz_left'][:,1],\n",
    "                 color='g',linewidth=1)\n",
    "#         print(\"lane coordinates right\", Test.map_api.get_lane_coords(lane)['xyz_right'][:,0])\n",
    "    x_mesh, y_mesh = get_grid(intersection_id, grid_boundary)\n",
    "#     print(x_mesh.shape, y_mesh[:,1])\n",
    "    plt.plot(x_mesh, y_mesh, c='grey', linewidth=0.1) # use plot, not scatter\n",
    "    plt.plot(np.transpose(x_mesh), np.transpose(y_mesh),c='grey', linewidth=0.1) # add this here\n",
    "#     plt.title(intersection_id,fontsize=30)\n",
    "    \n",
    "    for key, traj in veh_traj.items():\n",
    "        traj = np.array(traj)\n",
    "        plt.plot(traj[:,0],traj[:,1], c='b',linewidth=0.5)\n",
    "    for key, traj in ped_traj.items():\n",
    "        traj = np.array(traj)\n",
    "        plt.plot(traj[:,0],traj[:,1], c='orange',linewidth=0.5)\n",
    "    for key, traj in cyc_traj.items():\n",
    "        traj = np.array(traj)\n",
    "        plt.plot(traj[:,0],traj[:,1], c='cyan',linewidth=0.5)\n",
    "#     if veh is not None:\n",
    "#         for traj in veh: plt.plot(traj[:,0],traj[:,1], c='b',linewidth=0.5)\n",
    "#     if ped is not None:\n",
    "#         for traj in ped: plt.scatter(traj[:,0],traj[:,1], c='orange',linewidth=0.5)\n",
    "#     if cyc is not None:\n",
    "#         for traj in cyc: plt.plot(traj[:,0],traj[:,1], c='cyan',linewidth=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "# locate to the working folder\n",
    "# sys.path.append(\"D:\\\\GitHub\\\\Clone\\\\planning\\\\ruixuan\")\n",
    "from ruixuan.turning_scene import *\n",
    "from l5kit.rasterization.rasterizer_builder import _load_metadata\n",
    "import time\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"/home/lab1/repo/planning/prediction-dataset\"\n",
    "# get config\n",
    "cfg = load_config_data(\"/home/lab1/repo/planning/ruixuan/visualisation_config.yaml\")\n",
    "print(cfg)\n",
    "\n",
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open()\n",
    "print(zarr_dataset)\n",
    "\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "ego_dataset = EgoDataset(cfg, zarr_dataset, rast)\n",
    "# agent_dataset = AgentDataset(cfg, zarr_dataset, rast)\n",
    "# Obatin the information from semantic map\n",
    "\n",
    "semantic_map_filepath = dm.require(cfg[\"raster_params\"][\"semantic_map_key\"])\n",
    "dataset_meta = _load_metadata(cfg[\"raster_params\"][\"dataset_meta_key\"], dm)\n",
    "world_to_ecef = np.array(dataset_meta[\"world_to_ecef\"], dtype=np.float64)\n",
    "Map_Api = MapAPI(semantic_map_filepath, world_to_ecef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manully find the lane id in Map_Api for \"lane_merge\" and \"8KfB\"\n",
    "lane_list = {}\n",
    "junction_boundary = {}\n",
    "# extend lane sequences\n",
    "lane_list['lane_merge'] = ['ADrl',\"oFEC\",'m0JU','iQgg','M5V5','/Pgg','FFEC','XHTU']\n",
    "lane_list['8KfB'] = ['/24B','6p63','FV1O','MV/U','SxVb','TG2b','TZZv','ZnUV','bH1o','dddQ','nXc0','zHjP','SD8o','vC8o']\n",
    "junction_boundary['lane_merge'] = [(-940,1380),(-940,1480),(-880,1380),(-880,1480)]\n",
    "junction_boundary['8KfB'] = [(500,-2420),(500,-2360),(560,-2360),(560,-2420)]\n",
    "# junction_boundary['8KfB'] = [(450,-2400),(500,-2360),(560,-2360),(560,-2420)]\n",
    "\n",
    "grid_boundary={}\n",
    "grid_boundary['8KfB']={'X':[450,600], 'Y':[-2450, -2300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectory(Scene):\n",
    "    \n",
    "    def __init__(self, dataset, Map_Api):\n",
    "        super(Trajectory, self).__init__(dataset, Map_Api)\n",
    "        self.label_name = ['Car','Van','Tram','Bus','Truck','EV','OV','Bicycle',\\\n",
    "                           'Motorcycle','Cyclist','Motorcyclist','Pedestrian']\n",
    "        self.label_idx = list(range(3,15))\n",
    "        self.label_dict = dict(zip(self.label_name, self.label_idx))\n",
    "        self.all_traffic_control = None\n",
    "        self.Traffic_Control = None\n",
    "\n",
    "    def generate_info_from_MAP(self):\n",
    "        self.all_junctions = self.get_elements(\"junction\")\n",
    "        self.all_lanes = self.get_elements(\"lane\")\n",
    "        self.all_traffic_control = self.get_elements(\"traffic_control_element\")\n",
    "        self.Lane = {self.map_api.id_as_str(lane.id):lane.element.lane for lane in self.all_lanes}\n",
    "        self.Junction = {self.map_api.id_as_str(junction.id):junction for junction in self.all_junctions}\n",
    "        self.Traffic_Control = {self.map_api.id_as_str(traffic_control.id):traffic_control.element for traffic_control in self.all_traffic_control}\n",
    "        \n",
    "        for junction in self.all_junctions:\n",
    "            self.Junction_Lane[self.map_api.id_as_str(junction.id)] = []\n",
    "\n",
    "            for lane in junction.element.junction.lanes:\n",
    "                self.Junction_Lane[self.map_api.id_as_str(junction.id)].append(self.map_api.id_as_str(lane))\n",
    "\n",
    "            self.Junction_Lane[self.map_api.id_as_str(junction.id)] = set(self.Junction_Lane[self.map_api.id_as_str(junction.id)])\n",
    "        \n",
    "        self.junction_scene = dict.fromkeys(list(self.Junction.keys()), [])\n",
    "        self.junction_turning_scene = dict.fromkeys(list(self.Junction.keys()), {})\n",
    "        for key in self.Junction.keys():\n",
    "            self.junction_turning_scene[key] = {'Turning Left': [], 'Turning Right': []}    \n",
    "        \n",
    "        \n",
    "    def label_loc_check(self, target_label):\n",
    "    \n",
    "        agent_id_list = self.agent_list[self.label_dict[target_label]-3]\n",
    "\n",
    "        for agent_id in agent_id_list:\n",
    "            agent_loc = self.agent_centroid[np.where(self.agent_id==agent_id)[0]]\n",
    "            for centroid in agent_loc:\n",
    "                if self.Junction_region.contains(Point(centroid[0],centroid[1])):\n",
    "                    return True\n",
    "    \n",
    "    def junction_lane_visualize(self, junction_id):\n",
    "        \n",
    "        plt.figure(figsize=(18,18))\n",
    "        \n",
    "        lane_list = self.Junction_Lane[junction_id]\n",
    "        \n",
    "        for lane in lane_list:\n",
    "            plt.plot(self.map_api.get_lane_coords(lane)['xyz_left'][:,0].tolist()+ self.map_api.get_lane_coords(lane)['xyz_right'][:,0].tolist(),\n",
    "                        self.map_api.get_lane_coords(lane)['xyz_left'][:,1].tolist()+ self.map_api.get_lane_coords(lane)['xyz_right'][:,1].tolist(),\n",
    "                        marker='x', label = lane)\n",
    "\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(which='both')\n",
    "        plt.legend(fontsize=20)\n",
    "        axes = plt.gca()  \n",
    "    \n",
    "                \n",
    "    def agent_trajectory(self, scene, target_label, junction_boundary):\n",
    "\n",
    "        self.scene = scene\n",
    "        self.target_label = target_label\n",
    "#         self.junction = junction\n",
    "        # region for junction \"sGK1\"\n",
    "#         junction_boundary = {junction:[(300,-1150),[300,-1100],(340,-1100),(340,-1150)]}\n",
    "\n",
    "        # region for junction \"8KfB\"\n",
    "#         junction_boundary = {junction:[(500,-2420),(500,-2360),(560,-2360),(560,-2420)]}\n",
    "        \n",
    "        # region for lane merge\n",
    "#         junction_boundary = {junction:[(-940,1380),(-940,1480),(-880,1380),(-880,1480)]}\n",
    "\n",
    "        self.Junction_region = Polygon(junction_boundary)\n",
    "\n",
    "        self.agent_list = []\n",
    "        frame_interval = self.dataset.scenes[scene]['frame_index_interval']\n",
    "        agent_interval_begin = self.dataset.frames[frame_interval[0]]['agent_index_interval'][0]\n",
    "        agent_interval_end = self.dataset.frames[frame_interval[1]-1]['agent_index_interval'][1]\n",
    "        self.agent_id = self.dataset.agents[agent_interval_begin:agent_interval_end]['track_id']\n",
    "        agent_label_prob = self.dataset.agents[agent_interval_begin:agent_interval_end]['label_probabilities']\n",
    "        self.agent_centroid = self.dataset.agents[agent_interval_begin:agent_interval_end]['centroid']\n",
    "\n",
    "        for label in self.label_idx:\n",
    "            valid_idx = np.where(agent_label_prob[:,label]>0.5)[0]\n",
    "            valid_id = set(self.agent_id[valid_idx])\n",
    "            self.agent_list.append(list(valid_id))\n",
    "\n",
    "        if len(self.agent_list[self.label_dict[target_label]-3])>0 and self.label_loc_check(target_label):\n",
    "            return [scene]\n",
    "        else:\n",
    "            # print('Not feasible scene')\n",
    "            return []\n",
    "        \n",
    "    def get_agent_traj(self, scene, target_label, junction, lane_list):\n",
    "        veh_traj, ped_traj, cyclist_traj=[], [], [] \n",
    "        print(self.label_dict, self.label_dict[target_label])\n",
    "        for idx, agent_label in enumerate(self.agent_list):\n",
    "            print(\"xxx\", idx, agent_label)\n",
    "            for agent in agent_label:\n",
    "                agent_loc = self.agent_centroid[np.where(self.agent_id==agent)[0]]\n",
    "                if idx != self.label_dict[target_label]-3 and agent_loc.shape[0] > 30  \\\n",
    "                and np.linalg.norm(agent_loc[0,:]-agent_loc[-1,:]) > 5:\n",
    "                    veh_traj.append(agent_loc)\n",
    "#                     plt.plot(agent_loc[:,0],agent_loc[:,1],label='Agent ID '+str(agent)+': '\\\n",
    "#                              +self.label_name[idx], color=colors[idx])\n",
    "\n",
    "                elif idx== self.label_dict[target_label]-3:\n",
    "                    ped_traj.append(agent_loc)\n",
    "        veh_traj, ped_traj, cyclist_traj = np.array(veh_traj), np.array(ped_traj), np.array(cyclist_traj)\n",
    "        return veh_traj, ped_traj,cyclist_traj\n",
    "#                     plt.plot(agent_loc[:,0],agent_loc[:,1], color=colors[idx], marker='*')\n",
    "            \n",
    "            \n",
    "            \n",
    "    def trajectory_junction_visualize(self, scene, target_label, junction, lane_list):\n",
    "        \n",
    "        frame_interval = self.dataset.scenes[scene]['frame_index_interval']\n",
    "        \n",
    "        plt.figure(figsize=(18,18))\n",
    "\n",
    "        for lane in lane_list:\n",
    "            plt.plot(self.map_api.get_lane_coords(lane)['xyz_right'][:,0], self.map_api.get_lane_coords(lane)['xyz_right'][:,1],\n",
    "                     color='k',linewidth=5, alpha=0.2)\n",
    "            plt.plot(self.map_api.get_lane_coords(lane)['xyz_left'][:,0], self.map_api.get_lane_coords(lane)['xyz_left'][:,1],\n",
    "                     color='k',linewidth=5, alpha=0.2)\n",
    "\n",
    "        cmap = plt.get_cmap('gnuplot')    \n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "         '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf','maple','yellowgreen'] \n",
    "\n",
    "        for idx, agent_label in enumerate(self.agent_list):\n",
    "            for agent in agent_label:\n",
    "                agent_loc = self.agent_centroid[np.where(self.agent_id==agent)[0]]\n",
    "                if idx != self.label_dict[target_label]-3 and agent_loc.shape[0] > 30  and np.linalg.norm(agent_loc[0,:]-agent_loc[-1,:]) > 5:\n",
    "                    plt.plot(agent_loc[:,0],agent_loc[:,1],label='Agent ID '+str(agent)+': '+self.label_name[idx], color=colors[idx])\n",
    "\n",
    "                elif idx== self.label_dict[target_label]-3:\n",
    "                    plt.plot(agent_loc[:,0],agent_loc[:,1], color=colors[idx], marker='*')\n",
    "\n",
    "        ego_translation = self.frames[frame_interval[0]:frame_interval[1]]['ego_translation']\n",
    "        plt.plot(ego_translation[:,0],ego_translation[:,1],label='Ego',color='r')\n",
    "        turn = ' Left Turn' if rotation33_as_yaw(self.frames[frame_interval[0]]['ego_rotation']) - rotation33_as_yaw(self.frames[frame_interval[1]-1]['ego_rotation']) < 0 else ' Right Turn'\n",
    "\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(which='both')\n",
    "        plt.legend(fontsize=20,loc='best')\n",
    "        plt.title('Trajectory : Scene '+str(scene)+turn+' at Junction '+junction, fontsize=30)\n",
    "        axes = plt.gca()\n",
    "        \n",
    "#     def agents_state_find(self, scene, output_array, target_agent_type_list):\n",
    "        \n",
    "#         frame_interval = .dataset.scenes[scene]['frame_index_interval']\n",
    "        \n",
    "#         cars_list = target_agent_type_list[0]\n",
    "#         pedestrian_list = target_agent_type_list[1]\n",
    "        \n",
    "#         for agent_list in target_agent_type_list:\n",
    "#             for agent in agent_list:\n",
    "#                     agent_loc = self.agent_centroid[np.where(self.agent_id==agent)[0]]\n",
    "#                     if idx != self.label_dict[target_label]-3 and agent_loc.shape[0] > 30  and np.linalg.norm(agent_loc[0,:]-agent_loc[-1,:]) > 5:\n",
    "#                         for frame in frames\n",
    "\n",
    "#                     elif idx== self.label_dict[target_label]-3:\n",
    "#                         plt.plot(agent_loc[:,0],agent_loc[:,1], color=colors[idx], marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = Trajectory(zarr_dataset, Map_Api)\n",
    "Test.generate_info_from_MAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(intersection_id,grid_boundary):\n",
    "    x = grid_boundary[intersection_id]['X']\n",
    "    y = grid_boundary[intersection_id]['Y']\n",
    "    x_ = np.linspace(x[0], x[1],500)\n",
    "    y_ = np.linspace(y[0], y[1],500)\n",
    "    x_mesh, y_mesh = np.meshgrid(x_, y_)\n",
    "    return x_mesh, y_mesh\n",
    "\n",
    "def locate_in_mesh(x_mesh, y_mesh, point):\n",
    "    x, y = point[0], point[1]\n",
    "    result=[]\n",
    "#     print(x, y, x_mesh[0], x_mesh[-1], y_mesh[0], y_mesh[-1])\n",
    "    if x>x_mesh[-1] or x<x_mesh[0] or y>y_mesh[-1] or y<y_mesh[0]:\n",
    "        return None\n",
    "    result = [math.floor(x-x_mesh[0]), math.floor(y-y_mesh[0])]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replot_from_representation(output[2], lane_list=lane_list, intersection_id='8KfB',  \\\n",
    "                           grid_boundary=grid_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
