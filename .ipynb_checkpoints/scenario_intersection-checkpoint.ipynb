{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instant-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDataset, AgentDataset\n",
    "from l5kit.geometry.transform import *\n",
    "\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.geometry import transform_points, rotation33_as_yaw\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from l5kit.rasterization.rasterizer_builder import _load_metadata\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import os\n",
    "\n",
    "# from l5kit.visualization.visualizer.zarr_utils import zarr_to_visualizer_scene\n",
    "# from l5kit.visualization.visualizer.visualizer import visualize\n",
    "from bokeh.io import output_notebook, show\n",
    "from l5kit.data import MapAPI\n",
    "from IPython.display import display, clear_output\n",
    "import PIL\n",
    "\n",
    "from scenario import get_lanes, lane_check, current_lane\n",
    "\n",
    "\n",
    "import matlab\n",
    "import matlab.engine\n",
    "\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "animal-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_version': 4, 'model_params': {'model_architecture': 'resnet50', 'history_num_frames': 0, 'future_num_frames': 50, 'step_time': 0.1}, 'raster_params': {'raster_size': [320, 320], 'pixel_size': [0.5, 0.5], 'ego_center': [0.6, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5, 'disable_traffic_light_faces': False, 'set_origin_to_bottom': True}, 'val_data_loader': {'key': 'scenes/train.zarr', 'batch_size': 12, 'shuffle': False, 'num_workers': 16}}\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# set env variable for data\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"C:\\\\Users\\\\zheng\\\\Desktop\\\\UMich\\\\Independent Study\\\\prediction-dataset\"\n",
    "# get config\n",
    "cfg = load_config_data(\"C:\\\\Users\\\\zheng\\\\Desktop\\\\UMich\\\\Independent Study\\\\Codes\\\\python codes\\\\visualisation_config.yaml\")\n",
    "print(cfg)\n",
    "\n",
    "dm = LocalDataManager()\n",
    "dataset_path = dm.require(cfg[\"val_data_loader\"][\"key\"])\n",
    "zarr_dataset = ChunkedDataset(dataset_path)\n",
    "zarr_dataset.open()\n",
    "print(zarr_dataset)\n",
    "\n",
    "rast = build_rasterizer(cfg, dm)\n",
    "ego_dataset = EgoDataset(cfg, zarr_dataset, rast)\n",
    "# agent_dataset = AgentDataset(cfg, zarr_dataset, rast)\n",
    "# Obatin the information from semantic map\n",
    "\n",
    "semantic_map_filepath = dm.require(cfg[\"raster_params\"][\"semantic_map_key\"])\n",
    "dataset_meta = _load_metadata(cfg[\"raster_params\"][\"dataset_meta_key\"], dm)\n",
    "world_to_ecef = np.array(dataset_meta[\"world_to_ecef\"], dtype=np.float64)\n",
    "Map_Api = MapAPI(semantic_map_filepath, world_to_ecef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-hypothetical",
   "metadata": {},
   "source": [
    "## Now check the lane-junction relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "decent-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scene(object):\n",
    "    def __init__(self, dataset, Map_Api):\n",
    "        self.dataset = dataset\n",
    "        self.frames = self.dataset.frames\n",
    "        self.scene_num = len(self.dataset.scenes)\n",
    "        self.yaw_th = 1.25\n",
    "        self.distance_th = 10\n",
    "        self.eng = matlab.engine.start_matlab()\n",
    "        self.eng.cd(r'D:\\GitHub\\Clone\\planning\\utils') \n",
    "        self.turning_scenes = []\n",
    "        self.turning_yaw_diff = {}\n",
    "        self.tunring_frames = []\n",
    "        self.map_api = Map_Api\n",
    "        self.all_junctions = None\n",
    "        self.all_lanes = None\n",
    "        self.Junction_Lane = {}\n",
    "        self.Lane = None\n",
    "        self.Junctions = None\n",
    "        self.junction_scene = {}\n",
    "        self.junction_turning_scene = {}\n",
    "        self.error_filtered_scene = []\n",
    "        \n",
    "        \n",
    "    \n",
    "    def is_element(self, elem, element_name):\n",
    "        return elem.element.HasField(element_name)\n",
    "\n",
    "    def get_elements(self, element_name):\n",
    "        return [elem for elem in self.map_api.elements if self.is_element(elem, element_name)]\n",
    "\n",
    "    \n",
    "    def lane_check(self, centroid, lane_id):\n",
    "        point = Point(centroid[0],centroid[1])\n",
    "        boundary = self.map_api.get_lane_coords(lane_id)\n",
    "        left_boundary = boundary['xyz_left']\n",
    "        right_boundary = boundary['xyz_right']\n",
    "        left_boundary_point = [(line[0],line[1])for line in left_boundary]\n",
    "        right_boundary_point = [(line[0],line[1])for line in reversed(right_boundary)]\n",
    "        polygon = Polygon(left_boundary_point+right_boundary_point)\n",
    "\n",
    "        return polygon.contains(point)\n",
    "\n",
    "\n",
    "    def current_lane(self, centroid):\n",
    "\n",
    "        for key, value in self.Lane.items():\n",
    "            if self.lane_check(centroid, key):\n",
    "                return key\n",
    "    \n",
    "\n",
    "    def generate_info_from_MAP(self):\n",
    "        self.all_junctions = self.get_elements(\"junction\")\n",
    "        self.all_lanes = self.get_elements(\"lane\")\n",
    "        self.Lane = {self.map_api.id_as_str(lane.id):lane.element.lane for lane in self.all_lanes}\n",
    "        self.Junction = {self.map_api.id_as_str(junction.id):junction for junction in self.all_junctions}\n",
    "        \n",
    "        for junction in self.all_junctions:\n",
    "            self.Junction_Lane[self.map_api.id_as_str(junction.id)] = []\n",
    "\n",
    "            for lane in junction.element.junction.lanes:\n",
    "                self.Junction_Lane[self.map_api.id_as_str(junction.id)].append(self.map_api.id_as_str(lane))\n",
    "\n",
    "            self.Junction_Lane[self.map_api.id_as_str(junction.id)] = set(self.Junction_Lane[self.map_api.id_as_str(junction.id)])\n",
    "        \n",
    "        self.junction_scene = dict.fromkeys(list(self.Junction.keys()), [])\n",
    "        self.junction_turning_scene = dict.fromkeys(list(self.Junction.keys()), {})\n",
    "        for key in self.Junction.keys():\n",
    "            self.junction_turning_scene[key] = {'Turning Left': [], 'Turning Right': []}\n",
    "        \n",
    "        \n",
    "    def trajectory_visualize(self):\n",
    "        plt.figure(figsize=(18,18))\n",
    "        plt.scatter(self.frames[\"ego_translation\"][:,0], self.frames[\"ego_translation\"][:,1], marker='.')\n",
    "        plt.scatter(self.frames[\"ego_translation\"][self.tunring_frames,0], self.frames[\"ego_translation\"][self.tunring_frames,1], marker='.', color='r')\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(which='both')\n",
    "        axes = plt.gca()\n",
    "        \n",
    "    \n",
    "     def scene_visualize(self, scene_idx):\n",
    "        \n",
    "        indexes = ego_dataset.get_scene_indices(scene_idx)\n",
    "        images = []\n",
    "\n",
    "        for idx in indexes:\n",
    "\n",
    "            data = ego_dataset[idx]\n",
    "            im = data[\"image\"].transpose(1, 2, 0)\n",
    "            im = ego_dataset.rasterizer.to_rgb(im)\n",
    "            target_positions_pixels = transform_points(data[\"target_positions\"], data[\"raster_from_agent\"])\n",
    "            center_in_pixels = np.asarray(cfg[\"raster_params\"][\"ego_center\"]) * cfg[\"raster_params\"][\"raster_size\"]\n",
    "        #     draw_trajectory(im, target_positions_pixels, TARGET_POINTS_COLOR, yaws=data[\"target_yaws\"])\n",
    "            clear_output(wait=True)\n",
    "            display(PIL.Image.fromarray(im))\n",
    "                     \n",
    "            \n",
    "    def junction_visualize(self, junction_id):\n",
    "        \n",
    "        plt.figure(figsize=(18,18))\n",
    "        plt.scatter(SCENE.frames[\"ego_translation\"][:,0], SCENE.frames[\"ego_translation\"][:,1], marker='.')\n",
    "        \n",
    "        lane_list = self.Junction_Lane[junction_id]\n",
    "        \n",
    "        for lane in lane_list:\n",
    "            plt.scatter(self.map_api.get_lane_coords(lane)['xyz_left'][:,0], self.map_api.get_lane_coords(lane)['xyz_left'][:,1], marker='.', color='k')\n",
    "            plt.scatter(self.map_api.get_lane_coords(lane)['xyz_right'][:,0], self.map_api.get_lane_coords(lane)['xyz_right'][:,1], marker='.', color='k')\n",
    "\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(which='both')\n",
    "        axes = plt.gca()\n",
    "    \n",
    "        \n",
    "    def turning_scenes_finding(self):\n",
    "        \n",
    "        bar = tqdm(range(self.scene_num))\n",
    "        bar.set_description('Filtering the turning scenes: ')\n",
    "        for scene in bar:\n",
    "\n",
    "            start_frame = self.frames[self.dataset.scenes[scene][\"frame_index_interval\"][0]]\n",
    "            finish_frame = self.frames[self.dataset.scenes[scene][\"frame_index_interval\"][1]-1]\n",
    "\n",
    "            start_yaw = rotation33_as_yaw(start_frame[\"ego_rotation\"])\n",
    "            finish_yaw = rotation33_as_yaw(finish_frame[\"ego_rotation\"])\n",
    "\n",
    "\n",
    "            if abs(start_yaw-finish_yaw) > self.yaw_th:\n",
    "                self.turning_scenes.append(scene)\n",
    "                self.tunring_frames += list(range(self.dataset.scenes[scene][\"frame_index_interval\"][0],self.dataset.scenes[scene][\"frame_index_interval\"][1]))\n",
    "                \n",
    "    \n",
    "   \n",
    "    def chgpt_index_find(self, chgpt_loc, chgpt_dist, chgpt_num):\n",
    "        rel_d = np.diff(chgpt_loc)\n",
    "        \n",
    "        while True in (rel_d < self.distance_th):\n",
    "            for idx, d in enumerate(rel_d):\n",
    "                if d < self.distance_th:\n",
    "                    index = chgpt_loc[idx] if chgpt_dist[chgpt_loc[idx]]< chgpt_dist[chgpt_loc[idx+1]] else chgpt_loc[idx+1]\n",
    "                    chgpt_dist[index] = 0\n",
    "            chgpt_loc = np.argpartition(chgpt_dist, -chgpt_num)[-chgpt_num:]\n",
    "            chgpt_loc.sort()\n",
    "            # find the adjacent distance\n",
    "            rel_d = np.diff(chgpt_loc)\n",
    "            \n",
    "            \n",
    "        return chgpt_loc\n",
    "\n",
    "    \n",
    "            \n",
    "    def scene_turning_frames(self, scene_idx):\n",
    "        \n",
    "        frames = list(range(self.dataset.scenes[scene_idx][\"frame_index_interval\"][0],self.dataset.scenes[scene_idx][\"frame_index_interval\"][1]))\n",
    "        yaw = [rotation33_as_yaw(rotation) for rotation in self.dataset.frames['ego_rotation'][frames]]\n",
    "        \n",
    "        # extract key info from MATLAB results\n",
    "        output_yaw = self.eng.mat2py(matlab.double(yaw), nargout=2)\n",
    "\n",
    "        chgpt_dist_yaw = np.array(output_yaw[0])[0]\n",
    "        chgpt_num_dist_yaw = np.array(output_yaw[1]).flatten()\n",
    "\n",
    "        chgpt_num = np.argmax(chgpt_num_dist_yaw)\n",
    "        \n",
    "        \n",
    "        if chgpt_num != 2:\n",
    "            self.error_filtered_scene.append(scene_idx)\n",
    "            \n",
    "            return []\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            chgpt_index = np.argpartition(chgpt_dist_yaw, -chgpt_num)[-chgpt_num:]\n",
    "            chgpt_index.sort()\n",
    "\n",
    "            chgpt_loc = self.chgpt_index_find(chgpt_index, chgpt_dist_yaw, chgpt_num)\n",
    "\n",
    "            self.turning_yaw_diff[scene_idx] = yaw[chgpt_loc[0]] - yaw[chgpt_loc[1]]\n",
    "\n",
    "\n",
    "            return list(range(chgpt_loc[0]+frames[0],chgpt_loc[1]+frames[0],3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def lanes_at_turning(self, scene_turning_frames):\n",
    "        \n",
    "        lanes = []\n",
    "\n",
    "        for frame in scene_turning_frames:\n",
    "            lanes.append(self.current_lane(self.frames[frame]['ego_translation'][:2]))\n",
    "\n",
    "        lanes = set(lanes)\n",
    "\n",
    "        return lanes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def junction_id_find(self, lanes):\n",
    "        junction_id = []\n",
    "\n",
    "        \n",
    "        for key in self.Junction_Lane.keys():\n",
    "\n",
    "            if len(self.Junction_Lane[key]&lanes) > 0:\n",
    "                junction_id.append(key)\n",
    "                return junction_id\n",
    "                \n",
    "                \n",
    "        return junction_id\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def junction_scene_find(self, scene_idx, junction_id):\n",
    "    \n",
    "        self.junction_scene[junction_id] = self.junction_scene[junction_id] + [scene_idx]\n",
    "        \n",
    "        if self.turning_yaw_diff[scene_idx] > 0:\n",
    "            self.junction_turning_scene[junction_id]['Turning Right'] += [scene_idx]\n",
    "        else:\n",
    "            self.junction_turning_scene[junction_id]['Turning Left'] += [scene_idx]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "painted-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1661/1661 [3:08:33<00:00,  6.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# declare the object\n",
    "SCENE = Scene(zarr_dataset, Map_Api)\n",
    "\n",
    "# generate all necessary information from semantic MAP, including dictionaries of lane, junction and the lanes connected to junction\n",
    "SCENE.generate_info_from_MAP()\n",
    "\n",
    "# Filter the scenes containing turning decision based on the difference of yaws at starting and ending frame of ego\n",
    "SCENE.turning_scenes_finding()\n",
    "\n",
    "# For each turning scene, we first find out the frame interval that ego actually made its turn, and then extracted the lanes id covered\n",
    "# during this frame interval. Compare the lane set with the groudtruth set of each junction and its lanes, then we can know which junction \n",
    "# that ego was passing if it was passing a junction \n",
    "\n",
    "for turning_scene in tqdm(SCENE.turning_scenes):\n",
    "\n",
    "\n",
    "    scene_turning_frames = SCENE.scene_turning_frames(turning_scene)\n",
    "\n",
    "    if len(scene_turning_frames) > 0:\n",
    "\n",
    "        lanes = SCENE.lanes_at_turning(scene_turning_frames)\n",
    "        junction_id = SCENE.junction_id_find(lanes)\n",
    "\n",
    "        if len(junction_id) > 0:\n",
    "            SCENE.junction_scene_find(turning_scene, junction_id[0])\n",
    "            \n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-march",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
