{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from model import _build_model\n",
    "from corex import Graph\n",
    "\n",
    "import sys \n",
    "from ruixuan.turning_scene import *\n",
    "from l5kit.rasterization.rasterizer_builder import _load_metadata\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from tabulate import tabulate\n",
    "from utils import Gibbs_sampling, get_smoothness, get_distance_pt\n",
    "from config import Config\n",
    "from visualizer import plot_scene_on_grid\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new a graph  \n",
    "env = Graph()\n",
    "sample = env.sample\n",
    "# act/plan the 10 steps\n",
    "\n",
    "# add use the history info in target to sample\n",
    "\n",
    "# visualize the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human driving reward\n",
    "import pickle\n",
    "tasks = pickle.load(open(\"/home/lab1/repo/planning/tasks/task.pickle\",'rb'))\n",
    "task = tasks[0]\n",
    "\n",
    "\n",
    "\n",
    "#accumulateed jerkiness (smoothness), propasitional stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modelxg_universal_episode_history.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c51ef18df560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# reward_history =np.load('modelxf_universal_episode_history.npy',allow_pickle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# reward_history =np.load('modelxj_universal_episode_history.npy',allow_pickle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mreward_history\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelxg_universal_episode_history.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modelxg_universal_episode_history.npy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# reward_history = np.load('episode_history_collision_g2.npy', allow_pickle=True)\n",
    "# reward_history = np.load('simple_model2_episode_history.npy', allow_pickle=True) \n",
    "# reward_history = np.load('simple_model_episode_history_lowc.npy', allow_pickle=True)\n",
    "# reward_history = np.load('rightturn_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('through_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('through2_episode_history.npy', allow_pickle=True) \n",
    "# reward_history = np.load('guided_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided2_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided3_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided3x_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided3y_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided3a_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided3z_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('guided3y1_exp_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model4_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model6_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model5_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model7_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model8_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model9_all_episode_history.npy', allow_pickle=True)[1000:]\n",
    "# reward_history = np.load('model8a_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('model8b_thru_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('modelx_thru_episode_history.npy', allow_pickle=True)\n",
    "reward_history = np.load('modelxa_thru_episode_history.npy', allow_pickle=True)[:700000]\n",
    "# reward_history = np.load('modelxb_all_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('modelxc_universal_episode_history.npy', allow_pickle=True)\n",
    "# reward_history = np.load('modelxd_universal_episode_history.npy', allow_pickle=True)\n",
    "# reward_history =np.load('modelxe_universal_episode_history.npy',allow_pickle=True)[:700000]\n",
    "# reward_history =np.load('modelxf_universal_episode_history.npy',allow_pickle=True)\n",
    "# reward_history =np.load('modelxj_universal_episode_history.npy',allow_pickle=True)\n",
    "reward_history =np.load('modelxg_universal_episode_history.npy',allow_pickle=True)\n",
    "x=[]\n",
    "step=10000\n",
    "for i in range(0, len(reward_history), step):\n",
    "    x.append(sum(reward_history[i:i+step])/step)\n",
    "# print(x.shape)\n",
    "plt.plot(range(len(x)), x)\n",
    "# plt.savefig(\"modelxa_thru_history\")\n",
    "# plt.savefig('modelxe_universal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# a=list(itertools.product(np.round(np.arange(-0.1,0.15,0.05), decimals=2), np.round(np.arange(-3,4,1), decimals=0)))\n",
    "# print(len(a),'\\n' ,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.37000000001272343\n",
      "0.37000000001272343 0.7209946046574617\n"
     ]
    }
   ],
   "source": [
    "epsilon_min = 0.1\n",
    "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
    "epsilon = 1\n",
    "epsilon_interval = (\n",
    "    epsilon_max - epsilon_min\n",
    ")\n",
    "print(epsilon_interval)\n",
    "i=0\n",
    "while i<700000: \n",
    "    epsilon -= epsilon_interval / 1000000\n",
    "    i+=1\n",
    "print(epsilon)\n",
    "epsilon = max(epsilon, epsilon_min)\n",
    "print(epsilon , np.random.rand(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
